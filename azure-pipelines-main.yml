trigger:
  branches:
    include:
      - main

# TODO - use default Agent Pool?
# TODO - do we want Windows agent to allow local downloads?
# when "pip downloading" - agent will download the relevant python binary according to the agent's underlying architecture
# example: charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl 
pool:
  # ensure to use ubuntu to mirror with Databricks compute vm
  vmImage: ubuntu-latest

variables:
  FEED_NAME: cdporgfeed
  ORG_NAME: dluhctst

steps:
- checkout: self

- task: UsePythonVersion@0
  inputs:
    versionSpec: '3.11'

- script: |
    python -m pip install --upgrade pip twine==6.0.1 keyring artifacts-keyring --index-url https://pypi.org/simple
  displayName: Install packaging tools

- script: |
    # Fetch latest `main` to compare with current branch
    git fetch origin main

    # Fetch the merged `requirements.txt` from the `main` branch
    git show origin/main:requirements.txt > old_requirements.txt || touch old_requirements.txt
    cp requirements.txt new_requirements.txt

    # Use `diff` to find new dependencies, ignoring lines starting with "#"
    diff old_requirements.txt new_requirements.txt | \
      grep "^>" | sed 's/^> //' | grep -v '^#' > added_packages.txt || true

    echo "New dependencies detected:"
    cat added_packages.txt || true

    # If no new dependencies were detected, fail the build
    if [ ! -s added_packages.txt ]; then
      echo "ERROR: No new dependencies detected in requirements.txt."
      echo "This pipeline must only be used when adding new dependencies."
      exit 1
    fi
  displayName: Detect newly added dependencies


# Download packages from PyPI into a temp folder
- script: |
    mkdir -p downloaded_packages
    python -m pip download -r added_packages.txt -d downloaded_packages
  displayName: Download packages from PyPI

#### TWINE UPLOAD TO FEED PYPI #####
- task: PipAuthenticate@1
  inputs:
    artifactFeeds: $(FEED_NAME)

- script: |
    twine upload \
      --repository-url https://pkgs.dev.azure.com/$(ORG_NAME)/_packaging/$(FEED_NAME)/pypi/upload/ \
      -u __token__ \
      -p $SYSTEM_ACCESSTOKEN \
      downloaded_packages/*
  displayName: Upload packages to Azure Artifacts feed
  env:
    SYSTEM_ACCESSTOKEN: $(System.AccessToken)


# ##### AZ UPLOAD FEED UNIVERSAL PACKAGE #####
# # Authenticate Azure CLI
# - script: |
#       pip install --upgrade pip --target /opt/az/lib/python3.13/site-packages/
#       echo $(System.AccessToken) | az devops login
#   displayName: 'Login to Azure DevOps CLI'

# # Upload newly downloaded packages to Azure Universal Package Feed
# - script: |
#     # # Enable script to exit on error
#     # set -e

#     # Define Universal Package Feed URL and organization
#     FEED_URL="https://pkgs.dev.azure.com/$(ORG_NAME)/_packaging/$(FEED_NAME)/universal/upload/"

#     # Loop through each package in the downloaded_packages folder
#     for PACKAGE_FILE in downloaded_packages/*; do

#       # Get the package name and version from the file path
#       PACKAGE_NAME=$(basename $PACKAGE_FILE | sed -E 's/([a-zA-Z0-9\-]+)-([0-9\.]+)-.*\.(whl|tar\.gz)$/\1/')
#       PACKAGE_VERSION=$(basename $PACKAGE_FILE | sed -E 's/^([^-]+)-([0-9]+\.[0-9]+\.[0-9]+).*$/\2/')
      
#       # Convert PACKAGE_NAME to lowercase
#       PACKAGE_NAME="${PACKAGE_NAME,,}"

#       # Retrieve absolute path of file
#       ABSOLUTE_PATH="$(pwd)/$PACKAGE_FILE"

#       echo "Processing package: $ABSOLUTE_PATH"

#       # Upload the package to the Universal Package Feed
#       echo "Uploading $PACKAGE_NAME version $PACKAGE_VERSION to $FEED_URL"
#       az artifacts universal publish \
#         --organization https://dev.azure.com/$(ORG_NAME) \
#         --feed $(FEED_NAME) \
#         --name $PACKAGE_NAME \
#         --version $PACKAGE_VERSION \
#         --path $ABSOLUTE_PATH
#     done
#   displayName: Upload Packages to Universal Feed
#   env:
#     SYSTEM_ACCESSTOKEN: $(System.AccessToken)



